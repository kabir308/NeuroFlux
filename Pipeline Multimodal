def multimodal_inference(text, image, audio):
    # Inférence Texte
    text_embed = distillbert(text)
    
    # Inférence Image
    img_embed = mobilenet(image)
    
    # Inférence Audio
    audio_embed = whisper_tiny(audio)
    
    # Fusion (ex: Concaténation + Attention)
    fused = attention_layer([text_embed, img_embed, audio_embed])
    
    # Décision finale
    return classifier(fused)
